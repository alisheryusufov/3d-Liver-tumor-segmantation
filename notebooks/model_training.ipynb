{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from model import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Loss Function\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        # target: [B, H, W, D], predict: [B, C, H, W, D]\n",
    "        target_oh = F.one_hot(target, num_classes=3).permute(0, 4, 1, 2, 3).float()\n",
    "        predict_soft = F.softmax(predict, dim=1)\n",
    "        \n",
    "        intersection = torch.sum(predict_soft * target_oh, dim=(2, 3, 4))\n",
    "        union = torch.sum(predict_soft, dim=(2, 3, 4)) + torch.sum(target_oh, dim=(2, 3, 4))\n",
    "        \n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning Module\n",
    "class Segmenter(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = UNet()\n",
    "        self.ce_loss = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.0, 3.0]))\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def transfer_batch_to_device(self, batch, device, dataloader_idx):\n",
    "        \"\"\"\n",
    "        This method overrides the default Lightning behavior.\n",
    "        It moves tensors to the GPU but converts TorchIO objects to plain dicts\n",
    "        to prevent the 'FileNotFoundError: data' error.\n",
    "        \"\"\"\n",
    "        if isinstance(batch, dict):\n",
    "            return {k: self.transfer_batch_to_device(v, device, dataloader_idx) for k, v in batch.items()}\n",
    "        elif isinstance(batch, (list, tuple)):\n",
    "            return [self.transfer_batch_to_device(v, device, dataloader_idx) for v in batch]\n",
    "        elif isinstance(batch, torch.Tensor):\n",
    "            return batch.to(device)\n",
    "        return batch\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch, stage):\n",
    "        img = batch[\"CT\"][\"data\"]\n",
    "        mask = batch[\"Label\"][\"data\"][:, 0].long()\n",
    "        logits = self(img)\n",
    "        loss = self.ce_loss(logits, mask) + self.dice_loss(logits, mask)\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss, img, logits, mask\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _, _, _ = self._shared_step(batch, \"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, img, logits, mask = self._shared_step(batch, \"val\")\n",
    "        if batch_idx == 0:\n",
    "            self.log_images(img, logits, mask)\n",
    "        return loss\n",
    "\n",
    "    def log_images(self, img, pred, mask):\n",
    "        pred_class = torch.argmax(pred, dim=1)\n",
    "        axial_slice = img.shape[-1] // 2\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax[0].imshow(img[0, 0, :, :, axial_slice].cpu(), cmap=\"bone\")\n",
    "        ax[0].imshow(np.ma.masked_where(mask[0, :, :, axial_slice].cpu() == 0, mask[0, :, :, axial_slice].cpu()), alpha=0.5, cmap=\"autumn\")\n",
    "        ax[0].set_title(\"Ground Truth\")\n",
    "        \n",
    "        ax[1].imshow(img[0, 0, :, :, axial_slice].cpu(), cmap=\"bone\")\n",
    "        ax[1].imshow(np.ma.masked_where(pred_class[0, :, :, axial_slice].cpu() == 0, pred_class[0, :, :, axial_slice].cpu()), alpha=0.5, cmap=\"autumn\")\n",
    "        ax[1].set_title(\"Prediction\")\n",
    "        \n",
    "        self.logger.experiment.add_figure(\"Validation_Overlay\", fig, self.global_step)\n",
    "        plt.close()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pipeline\n",
    "def get_dataloaders():\n",
    "    path = Path(\"Task03_Liver_rs/imagesTr/\")\n",
    "    subjects = []\n",
    "    \n",
    "    for img_path in path.glob(\"liver_*\"):\n",
    "        label_path = Path(str(img_path).replace(\"imagesTr\", \"labelsTr\"))\n",
    "        if label_path.exists():\n",
    "            subjects.append(tio.Subject(\n",
    "                CT=tio.ScalarImage(img_path), \n",
    "                Label=tio.LabelMap(label_path)\n",
    "            ))\n",
    "\n",
    "    process = tio.Compose([\n",
    "        tio.CropOrPad((256, 256, 200)),\n",
    "        tio.RescaleIntensity(out_min_max=(0, 1))\n",
    "    ])\n",
    "    \n",
    "    augment = tio.RandomAffine(scales=(0.9, 1.1), degrees=10)\n",
    "    \n",
    "    train_idx = int(len(subjects) * 0.8)\n",
    "    train_ds = tio.SubjectsDataset(subjects[:train_idx], transform=tio.Compose([process, augment]))\n",
    "    val_ds = tio.SubjectsDataset(subjects[train_idx:], transform=process)\n",
    "\n",
    "    sampler = tio.data.LabelSampler(patch_size=96, label_probabilities={0: 0.1, 1: 0.4, 2: 0.5})\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        tio.Queue(train_ds, max_length=40, samples_per_volume=5, sampler=sampler), \n",
    "        batch_size=2, num_workers=0\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        tio.Queue(val_ds, max_length=40, samples_per_volume=5, sampler=sampler), \n",
    "        batch_size=2, num_workers=0\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, val_loader = get_dataloaders()\n",
    "    model = Segmenter(learning_rate=1e-4)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\", \n",
    "        dirpath=\"checkpoints/\", \n",
    "        filename=\"liver-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3, \n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1, \n",
    "        max_epochs=100,\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=[checkpoint_callback, LearningRateMonitor(logging_interval='epoch')],\n",
    "        logger=TensorBoardLogger(\"logs/\", name=\"Liver_Segmentation\")\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
